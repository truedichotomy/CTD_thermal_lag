{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- look into non-constant flow\n",
    "- write-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import gsw\n",
    "import netCDF4\n",
    "import dbdreader\n",
    "\n",
    "import correctSensorLag_Slater as csLag\n",
    "import correctThermalLag_Slater as ctLag\n",
    "import findThermalLagParams_TS_Slater as ftlpTS\n",
    "import findThermalLagParams_SP_Slater as ftlpSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignores divide by 0 errors in later step\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data and rename variables\n",
    "\n",
    "data_files = '/Users/jack/Documents/gliderData/sylvia-20180802/all_data/*.[D|E]BD'\n",
    "cac_dir = '/Users/jack/Documents/gliderData/sylvia-20180802/cache'\n",
    "\n",
    "#data_files = '/Users/jack/Documents/gliderData/all_electa_test/*.[d|e]bd'\n",
    "#cac_dir = '/Users/jack/Documents/gliderData/all_electa_cache_test'\n",
    "\n",
    "def prepare_data(data_files,cac_dir):\n",
    "    \"\"\"\n",
    "    Prepare data for analysis. Reads sensors for sensor list to be compiled into a dataframe and renames the dataframe columns. Assigns profile id\n",
    "    to each value, interpolates lat/lon data, removes invalid values, and converts units of specific variables.\n",
    "\n",
    "    Args:\n",
    "        data_files (string): Pathname to desired .EBD and .DBD files for a deployment\n",
    "        cac_dir (string): Pathname to directory housing associated cache files for a deployment\n",
    "\n",
    "    Returns:\n",
    "        Pandas dataframe (group) with glider data prepared for thermal lag correction\n",
    "    \"\"\"\n",
    "\n",
    "    sensors = ['sci_m_present_time','sci_water_pressure','sci_water_temp','sci_water_cond','m_lat','m_lon','m_tot_num_inflections']\n",
    "\n",
    "    dbd = dbdreader.MultiDBD(pattern=data_files,cacheDir=cac_dir) \n",
    "\n",
    "    tm,sensor_title=dbd.get(sensors[0])\n",
    "    sensor0_time_pair = np.column_stack((tm, sensor_title))\n",
    "    sensor0_time_pair = sensor0_time_pair[~((sensor0_time_pair[:, 0] < sensor0_time_pair[0,0]) | (sensor0_time_pair[:, 0] > sensor0_time_pair[-1,0]))]\n",
    "    #sensor0_time_pair[:,0] = pd.to_datetime(sensor0_time_pair[:,0], unit='s')\n",
    "    glider_sci = pd.DataFrame(sensor0_time_pair,columns=['time',sensors[0]])\n",
    "    #glider_sci['time'] = pd.to_datetime(glider_sci['time'])\n",
    "\n",
    "    for sensor_titles in sensors[1:]:\n",
    "        dbd=dbdreader.MultiDBD(pattern=data_files,cacheDir=cac_dir)    \n",
    "        tm,sensor_data=dbd.get(sensor_titles)\n",
    "        sensor_time_pair = np.column_stack((tm, sensor_data))\n",
    "        sensor_time_pair = sensor_time_pair[~((sensor_time_pair[:, 0] < sensor0_time_pair[0,0]) | (sensor_time_pair[:, 0] > sensor_time_pair[-1,0]))]\n",
    "        #sensor_time_pair[:,0] = pd.to_datetime(sensor_time_pair[:,0], unit='s')\n",
    "        sensor_time_df = pd.DataFrame(sensor_time_pair,columns=['time',sensor_titles])\n",
    "        #sensor_time_df['time'] = pd.to_datetime(sensor_time_df['time'])\n",
    "        glider_sci = glider_sci.merge(sensor_time_df, on='time', how='outer').sort_values(by='time')\n",
    "        glider_sci = glider_sci.reset_index(drop=True)\n",
    "\n",
    "    glider_sci['time'] = pd.to_datetime(glider_sci['time'], unit='s')\n",
    "\n",
    "    #drop all rows without ctd timestamp and duplicate ctd timestamps and rename columns and data frame to sci_data\n",
    "    sci_data = glider_sci.rename(columns={\"sci_m_present_time\": \"ctd_time\", \"sci_water_pressure\": \"pressure\", \"sci_water_temp\": \"temperature\", \\\n",
    "        \"sci_water_cond\": \"conductivity\",\"m_lat\":\"latitude\",\"m_lon\":\"longitude\"})\n",
    "\n",
    "    #assign profiles ids based on m_tot_num_inflections\n",
    "\n",
    "    #Forward and backfill m_tot_num_inflections variable so every value has an associated correct inflection count \n",
    "    sci_data['m_tot_num_inflections'].ffill(inplace=True)\n",
    "    sci_data['m_tot_num_inflections'].bfill(inplace=True)\n",
    "\n",
    "    #Linear interpolation of latitude and longitude variables\n",
    "    sci_data['latitude'] = sci_data['latitude'].interpolate()\n",
    "    sci_data['longitude'] = sci_data['longitude'].interpolate()\n",
    "\n",
    "    #Drop all invalid and duplicate ctd timestamps and invalid lat/lon values\n",
    "    sci_data = sci_data[sci_data['ctd_time'].ne(pd.Timestamp('1970-01-01 00:00:00.00'))].dropna(subset=['ctd_time']) \n",
    "    sci_data = sci_data.drop_duplicates(subset=['ctd_time'])\n",
    "    sci_data = sci_data[sci_data['latitude'].ne(0)].dropna(subset=['latitude'])\n",
    "    sci_data = sci_data[sci_data['longitude'].ne(0)].dropna(subset=['longitude'])\n",
    "    sci_data = sci_data.dropna(subset=['pressure'])\n",
    "\n",
    "    #Create profile_id column based on when the m_tot_num_inflections variable iterates\n",
    "    sci_data['profile_id'] = sci_data.groupby('m_tot_num_inflections').ngroup()\n",
    "    sci_data.reset_index(drop=True,inplace=True) #reset indices\n",
    "\n",
    "    sci_data['pressure'] = sci_data['pressure'].mul(10) #convert pressure from bar to dbar\n",
    "    sci_data['z'] = gsw.z_from_p(sci_data['pressure'].values,sci_data['latitude'].values) #calculate depth from pressure using gsw\n",
    "    sci_data['conductivity_ms_cm'] = sci_data['conductivity'].mul(10) #convert conductivity from s/m to ms/cm\n",
    "    sci_data['salinity'] = gsw.SP_from_C(sci_data['conductivity_ms_cm'].values,\\\n",
    "                                        sci_data['temperature'].values,sci_data['pressure'].values) # calculate salinity using gsw\n",
    "    \n",
    "    sci_data = sci_data.dropna(subset=['z'])\n",
    "\n",
    "    return sci_data\n",
    "\n",
    "sci_data = prepare_data(data_files,cac_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\") #groupby profile ID\n",
    "\n",
    "def drop_top_and_bottom(group,top_cut,bottom_cut):\n",
    "    \"\"\"\n",
    "    Removes specified meters from top and bottom of every profile\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "        top_cut (int or float): Meters to be removed from top of profile\n",
    "        bottom_cut (int or float): Meters to be removed from bottom of profile\n",
    "\n",
    "    Returns:\n",
    "        Profiles with top and bottom meters cut off\n",
    "    \"\"\"\n",
    "    group.drop(group[group['z'] > -top_cut].index, inplace=True)\n",
    "    group.drop(group[group['z'] < (group['z'].min()+bottom_cut)].index, inplace=True)\n",
    "    return group\n",
    "\n",
    "sci_data = profile_groups.apply(drop_top_and_bottom, 2, 2)\n",
    "sci_data.reset_index(drop=True,inplace=True) #reset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "profile_stats = pd.DataFrame() #create dataframe for profile statistics\n",
    "\n",
    "def set_profile_time(group):\n",
    "    \"\"\"\n",
    "    Assigns central time in each profile to all values in profile as profile_time\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Profile stats dataframe with profile_time column\n",
    "    \"\"\"\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "    n_points = group['ctd_time'].size\n",
    "    profile_time = group.iloc[n_points//2]['ctd_time']\n",
    "    profile_stats.loc[profile_id,'profile_time'] = profile_time\n",
    "\n",
    "result = profile_groups.apply(set_profile_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "def lag_shift_smooth_data(group):\n",
    "    ## correction for ctd sensor response time (lag from measurement to recording).\n",
    "    # this is not used in practice, because pressure sensor lag is assumed to be 0.\n",
    "\n",
    "    # P_sensor_lag = 0 means no correction.\n",
    "    P_sensor_lag = 0 # 0, assuming pressure is recorded correctly and instantly as the CTD time stamp\n",
    "    T_sensor_lag = 0 \n",
    "\n",
    "    cond_Vol = 1.5; # based on diagram from Kim Martini of Sea-Bird.\n",
    "    cond_Q = 10; # flow rate in ml/s.\n",
    "    TC_sensor_lag = cond_Vol/cond_Q\n",
    "\n",
    "    #correct lag shift on pressure, z, and temperature usinf correctSensorLag function\n",
    "    group['pressure_lag_shifted'] = csLag.correctSensorLag(group['ctd_time'], group['pressure'], P_sensor_lag)\n",
    "    group['z_lag_shifted'] = csLag.correctSensorLag(group['ctd_time'], group['z'], P_sensor_lag)\n",
    "    group['temperature_lag_shifted'] = csLag.correctSensorLag(group['ctd_time'], group['temperature'], T_sensor_lag)\n",
    "    group['conductivity_lag_shifted'] = csLag.correctSensorLag(group['ctd_time'], group['conductivity'], TC_sensor_lag)\n",
    "\n",
    "    #smooth variables on 5 value rolling mean smoothing\n",
    "    mov_window = 5\n",
    "    group['pressure_lag_shifted_smooth'] = group['pressure_lag_shifted'].rolling(mov_window, min_periods=1, center=True).mean()\n",
    "    group['z_lag_shifted_smooth'] = group['z_lag_shifted'].rolling(mov_window, min_periods=1, center=True).mean()\n",
    "    group['conductivity_lag_shifted_smooth'] = group['conductivity_lag_shifted'].rolling(mov_window, min_periods=1, center=True).mean()\n",
    "    group['temperature_lag_shifted_smooth'] = group['temperature_lag_shifted'].rolling(mov_window, min_periods=1, center=True).mean()\n",
    "\n",
    "    # Thermister reponse correction for temperature data\n",
    "    # This step is neccesary. assuming tau_T = 0.53 sec. \n",
    "    # according to Kim Martini's slides:\n",
    "    # \"Response time for this temperature sensor construction can range from 0.1-0.6 seconds.\n",
    "    # This can vary depending on the pump and profiling speed of the platform.\"\n",
    "    # smooth raw temperature data. 3 measurement points corresponds to about 6 seconds.\n",
    "    # this avoids extremely large dT/dt, dT/dz\n",
    "\n",
    "    #calculate dT/dt\n",
    "    dt = group['ctd_time'].diff() \n",
    "    tlsm = group['temperature_lag_shifted_smooth'].diff()\n",
    "    dT_dt_smooth = np.divide(tlsm[1:,],dt[1:,])\n",
    "\n",
    "    tau_T = 0.53; # in seconds. nominal value is 0.5 second based on Johnson et al. 2007\n",
    "    group['temperature_response_corrected_smooth'] = group['temperature_lag_shifted_smooth']\n",
    "    group.iloc[1:]['temperature_response_corrected_smooth'] = group.iloc[1:]['temperature_response_corrected_smooth'].add(np.multiply(tau_T,dT_dt_smooth))\n",
    "\n",
    "    return group\n",
    "\n",
    "sci_data = profile_groups.apply(lag_shift_smooth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 Prepare Profile Data \n",
    "\n",
    "n_profiles = sci_data['profile_id'].nunique()\n",
    "\n",
    "# find profile direction (up or down), find real profiles (pressure range > 2 dbar)\n",
    "\n",
    "profile_pressure_range_cutoff = 5; # dbar\n",
    "temperature_diff_cutoff = 4; # C\n",
    "\n",
    "profile_stats['n_profile_values'] = sci_data.groupby('profile_id')['ctd_time'].agg('count')\n",
    "profile_stats['pressure_diff'] = sci_data.groupby('profile_id')['pressure'].agg('last') - sci_data.groupby('profile_id')['pressure'].agg('first')\n",
    "profile_stats['temperature_diff'] = sci_data.groupby('profile_id')['temperature'].agg('max') - sci_data.groupby('profile_id')['temperature'].agg('min')\n",
    "\n",
    "profile_stats['profile_direction'] = np.select([profile_stats['pressure_diff'] >= profile_pressure_range_cutoff, \\\n",
    "    profile_stats['pressure_diff'] <= -profile_pressure_range_cutoff],[1,-1],0) #1 is downcast, -1 is upcast, 0 is null\n",
    "\n",
    "profile_stats['stratification_flag'] = np.select([profile_stats['temperature_diff'] >= temperature_diff_cutoff],[1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "def find_interface_thickness_percentiles(group):\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "\n",
    "    if profile_stats.loc[profile_id,'stratification_flag'] == 1:\n",
    "\n",
    "        temp = group['temperature']\n",
    "        pressure = group['pressure']\n",
    "        temp = temp.sort_values(ascending=True)\n",
    "        p85 = temp.quantile(0.85)\n",
    "        p15 = temp.quantile(0.15)\n",
    "        idx85 = temp.iloc[:temp.searchsorted(p85)].idxmax()\n",
    "        idx15 = temp.iloc[temp.searchsorted(p15):].idxmin()\n",
    "        pres_bound1 = pressure[idx15]\n",
    "        pres_bound2 = pressure[idx85]\n",
    "        interface_thickness = np.abs(pres_bound1-pres_bound2)\n",
    "        profile_stats.loc[profile_id,'interface_thickness'] = interface_thickness\n",
    "\n",
    "    else:\n",
    "        interface_thickness = np.nan\n",
    "        profile_stats.loc[profile_id,'interface_thickness'] = interface_thickness\n",
    "\n",
    "def find_interface_thickness_Daniel(group):\n",
    "    \"\"\"\n",
    "    Calculates interface thickness of each profile as the pressure difference corresponding to the \n",
    "    middle \"70%\" of the temperature data, calculated as minimum temperature + 0.15 time temp diff and \n",
    "    vice versa\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Profile stats dataframe with interface_thickness column\n",
    "    \"\"\"\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "\n",
    "    if profile_stats.loc[profile_id,'stratification_flag'] == 1:\n",
    "        \n",
    "        temp = group['temperature']\n",
    "        pressure = group['pressure']\n",
    "        tempdiff = profile_stats.loc[profile_id,'temperature_diff']\n",
    "        mintemp = temp.min() + 0.15*tempdiff\n",
    "        maxtemp = temp.max() - 0.15*tempdiff\n",
    "        indices = temp[(temp >= mintemp) & (temp <= maxtemp)].index\n",
    "        interface_measurements_count = len(indices)\n",
    "        profile_stats.loc[profile_id,'interface_measurements_count'] = interface_measurements_count\n",
    "        max_pressure = pressure[indices].max()\n",
    "        min_pressure = pressure[indices].min()\n",
    "        interface_thickness = np.abs(max_pressure-min_pressure)\n",
    "        if np.isnan(interface_thickness):\n",
    "            interface_thickness = 0.1\n",
    "        profile_stats.loc[profile_id,'interface_thickness'] = interface_thickness\n",
    "\n",
    "    else:\n",
    "        interface_thickness = np.nan\n",
    "        profile_stats.loc[profile_id,'interface_thickness'] = interface_thickness\n",
    "\n",
    "result = profile_groups.apply(find_interface_thickness_Daniel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "def find_gradient_per_profile(group):\n",
    "    \"\"\"\n",
    "    Finds first and second order numpy gradient of dT/dz for each profile\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Profiles with gradient columns\n",
    "    \"\"\"\n",
    "    gradient1 = np.gradient(group['temperature_response_corrected_smooth'], group['z_lag_shifted_smooth'])\n",
    "    group['dT_dz_smooth'] = gradient1\n",
    "    gradient2 = np.gradient(group['dT_dz_smooth'], group['z_lag_shifted_smooth'])\n",
    "    group['d2T_dz2_smooth'] = gradient2\n",
    "    return group\n",
    "\n",
    "sci_data = profile_groups.apply(find_gradient_per_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "def find_thermocline_z_p(group):\n",
    "    \"\"\"\n",
    "    Calculates thermocline depth and pressure using the point of maximum dT/dz \n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Profile stats dataframe with thermocline_z and thermocline_pressure columns\n",
    "    \"\"\"\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "    ind_zrange = (group['z'] < -4) & (group['z'] > (2+group['z'].min()))\n",
    "    if group['z'][ind_zrange].empty:\n",
    "        profile_stats.loc[profile_id,'thermocline_z'] = np.nan\n",
    "        profile_stats.loc[profile_id,'thermocline_pressure'] = np.nan\n",
    "    else:\n",
    "        ind1 = group['dT_dz_smooth'].abs() == group['dT_dz_smooth'][ind_zrange].abs().max()\n",
    "        profile_stats.loc[profile_id,'thermocline_z'] = group['z_lag_shifted_smooth'][ind1].mean()\n",
    "        profile_stats.loc[profile_id,'thermocline_pressure'] = group['pressure_lag_shifted_smooth'][ind1].mean()\n",
    "\n",
    "result = profile_groups.apply(find_thermocline_z_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "def assign_TS_flag(group):\n",
    "    \"\"\"\n",
    "    Assign thermal lag flag as 1 (TS) or 0 (no correction) based on conditions\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Profile stats dataframe with thermal_lag_flag column\n",
    "    \"\"\"\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "    profile_stats.loc[profile_id,'thermal_lag_flag'] = 0\n",
    "\n",
    "    cond3 = group['pressure'].max() >= 10\n",
    "    cond4 = np.abs(profile_stats.loc[profile_id,'pressure_diff']) >= 10\n",
    "    cond5 = np.abs(profile_stats.loc[profile_id,'temperature_diff']) >= 1\n",
    "\n",
    "    if profile_id == 0:\n",
    "        cond1 = profile_stats.loc[profile_id,'profile_direction']*profile_stats.loc[(profile_id+1),'profile_direction'] == -1\n",
    "        profile_stats.loc[profile_id,'thermal_lag_flag'] = np.select([cond1 & cond3 & cond4 & cond5],[1],0)\n",
    "\n",
    "    elif profile_id<(n_profiles-1):\n",
    "        cond1 = profile_stats.loc[profile_id,'profile_direction']*profile_stats.loc[(profile_id+1),'profile_direction'] == -1\n",
    "        cond2 = profile_stats.loc[profile_id,'profile_direction']*profile_stats.loc[(profile_id-1),'profile_direction'] == -1\n",
    "        profile_stats.loc[profile_id,'thermal_lag_flag'] = np.select([(cond1 or cond2) & cond3 & cond4 & cond5],[1],0)\n",
    "\n",
    "    elif profile_id == (n_profiles-1):\n",
    "        cond2 = profile_stats.loc[profile_id,'profile_direction']*profile_stats.loc[(profile_id-1),'profile_direction'] == -1\n",
    "        profile_stats.loc[profile_id,'thermal_lag_flag'] = np.select([cond2 & cond3 & cond4 & cond5],[1],0)\n",
    "\n",
    "result = profile_groups.apply(assign_TS_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_groups = sci_data.groupby(\"profile_id\")\n",
    "\n",
    "def assign_SP_flag(group):\n",
    "    \"\"\"\n",
    "    Assign thermal lag flag as 2 (SP) or remain as current based on conditions\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Profile stats dataframe with updated thermal_lag_flag column\n",
    "    \"\"\"\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "    current = profile_stats.loc[profile_id, 'thermal_lag_flag']\n",
    "    cond6 = profile_stats.loc[profile_id, 'interface_thickness'] < 8\n",
    "    cond7 = ~np.isnan(profile_stats.loc[profile_id, 'interface_thickness'])\n",
    "    cond8 = profile_stats.loc[profile_id, 'interface_measurements_count'] <= 32\n",
    "    cond9 = group['pressure'].max() - profile_stats.loc[profile_id,'thermocline_pressure'] >= 2\n",
    "    cond10 = profile_stats.loc[profile_id,'thermocline_pressure'] - group['pressure'].min() >= 2\n",
    "    cond11 = profile_stats.loc[profile_id, 'thermal_lag_flag'] == 1\n",
    "\n",
    "    profile_stats.loc[profile_id,'thermal_lag_flag'] = np.select([cond6 & cond7 & cond8 & cond9 & cond10 & cond11],[2],current)\n",
    "\n",
    "result = profile_groups.apply(assign_SP_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "def assign_pair_group(group, profile_stats):\n",
    "    n_profiles = len(profile_stats)\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "    if profile_stats.loc[profile_id, 'thermal_lag_flag'] != 0:\n",
    "        if profile_id == 0:\n",
    "            if profile_stats.loc[(profile_id + 1), 'thermal_lag_flag'] != 0:\n",
    "                pair_group = profile_id + 1\n",
    "            else:\n",
    "                pair_group = np.nan\n",
    "        elif (profile_id == n_profiles - 1) and (profile_stats.loc[(profile_id - 1), 'thermal_lag_flag'] != 0):\n",
    "            pair_group = profile_id - 1\n",
    "        else:\n",
    "            below = np.abs(profile_stats.loc[profile_id, 'profile_time'] - profile_stats.loc[profile_id - 1, 'profile_time'])\n",
    "            above = np.abs(profile_stats.loc[profile_id, 'profile_time'] - profile_stats.loc[profile_id + 1, 'profile_time'])\n",
    "            if (below < above) and (profile_stats.loc[(profile_id - 1), 'thermal_lag_flag'] != 0):\n",
    "                pair_group = profile_id - 1\n",
    "            elif (below > above) and (profile_stats.loc[(profile_id + 1), 'thermal_lag_flag'] != 0):\n",
    "                pair_group = profile_id + 1\n",
    "            elif (below < above * 2) and (profile_stats.loc[(profile_id - 1), 'thermal_lag_flag'] != 0):\n",
    "                pair_group = profile_id - 1\n",
    "            elif (below > above * 2) and (profile_stats.loc[(profile_id + 1), 'thermal_lag_flag'] != 0):\n",
    "                pair_group = profile_id + 1\n",
    "            else:\n",
    "                pair_group = np.nan\n",
    "\n",
    "        profile_stats.loc[profile_id, 'pair_group_id'] = pair_group\n",
    "\n",
    "    return profile_stats\n",
    "\n",
    "# Iterate through profile groups and update profile_stats iteratively\n",
    "for name, group in profile_groups:\n",
    "    profile_stats = assign_pair_group(group, profile_stats)\n",
    "\n",
    "# Reset indices\n",
    "profile_stats.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thermal_lag_params(group, profile_groups, profile_stats):\n",
    "    \"\"\"\n",
    "    Performs correction using optimization function, then calculates final corrected profile values\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        sci_data_cor dataframe with new columns of corrected values\n",
    "    \"\"\"\n",
    "    profile_id = group.iloc[0]['profile_id']\n",
    "    if profile_stats.loc[profile_id,'thermal_lag_flag'] != 0:\n",
    "        try:\n",
    "\n",
    "            profile_id2 = profile_stats.loc[profile_id,'pair_group_id']\n",
    "            pair_group = profile_groups.get_group(profile_id2)\n",
    "            \n",
    "            time1 = np.array(group['ctd_time'])\n",
    "            temp1 = np.array(group['temperature'])\n",
    "            cond1 = np.array(group['conductivity'])\n",
    "            pres1 = np.array(group['pressure'])\n",
    "            thermocline_pres1 = profile_stats.loc[profile_id,'thermocline_pressure']\n",
    "            time2 = np.array(pair_group['ctd_time'])\n",
    "            temp2 = np.array(pair_group['temperature'])\n",
    "            cond2 = np.array(pair_group['conductivity'])\n",
    "            pres2 = np.array(pair_group['pressure'])\n",
    "            thermocline_pres2 = profile_stats.loc[profile_id2,'thermocline_pressure']\n",
    "            lat1 = np.array(group['latitude'])\n",
    "            lon1 = np.array(group['longitude'])\n",
    "            lat2 = np.array(pair_group['latitude'])\n",
    "            lon2 = np.array(pair_group['longitude'])\n",
    "\n",
    "            if profile_stats.loc[profile_id,'thermal_lag_flag'] == 1:\n",
    "                params = ftlpTS.findThermalLagParams_TS(time1, cond1, temp1, pres1, time2, cond2, temp2, pres2)\n",
    "\n",
    "            elif profile_stats.loc[profile_id,'thermal_lag_flag'] == 2:\n",
    "                params = ftlpSP.findThermalLagParams_SP(time1, cond1, temp1, pres1, thermocline_pres1, time2, cond2, temp2, pres2, thermocline_pres2)\n",
    "\n",
    "            [temp_inside1,cond_outside1] = ctLag.correctThermalLag(time1,cond1,temp1,params.x)\n",
    "            [temp_inside2,cond_outside2] = ctLag.correctThermalLag(time2,cond2,temp2,params.x)\n",
    "\n",
    "            salt_cor1 = gsw.SP_from_C(np.multiply(cond_outside1,10),temp1,pres1)\n",
    "\n",
    "            saltA_outside1 = gsw.SA_from_SP(salt_cor1,pres1,lon1,lat1)\n",
    "\n",
    "            ctemp_outside1 = gsw.CT_from_t(saltA_outside1, temp1, pres1)\n",
    "\n",
    "            ptemp_outside1 = gsw.pt_from_CT(saltA_outside1, ctemp_outside1)\n",
    "\n",
    "            rho_outside1 = gsw.rho(saltA_outside1,ctemp_outside1,pres1)\n",
    "\n",
    "            sigma0_outside1 = gsw.sigma0(saltA_outside1,ctemp_outside1)\n",
    "            \n",
    "            profile_stats.loc[profile_id,'alpha'] = params.x[0]\n",
    "            profile_stats.loc[profile_id,'tau'] = params.x[1]\n",
    "\n",
    "            group['cond_outside'] = cond_outside1\n",
    "            group['salt_outside'] = salt_cor1\n",
    "            group['saltA_outside'] = saltA_outside1\n",
    "            group['ctemp_outside'] = ctemp_outside1\n",
    "            group['ptemp_outside'] = ptemp_outside1\n",
    "            group['rho_outside'] = rho_outside1\n",
    "            group['sigma0_outside'] = sigma0_outside1\n",
    "\n",
    "            print(f'{profile_id} was corrected')\n",
    "        except Exception as e:\n",
    "            print(f'{profile_id} did not work')\n",
    "            print(e)\n",
    "        return group\n",
    "    else:\n",
    "        print(f'{profile_id} was not processed')\n",
    "\n",
    "sci_data_cor = profile_groups.apply(run_thermal_lag_params, profile_groups, profile_stats)\n",
    "sci_data_cor.reset_index(drop=True,inplace=True) #reset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "profile_groups_cor = sci_data_cor.groupby('profile_id')\n",
    "profile_groups = sci_data.groupby('profile_id')\n",
    "\n",
    "def before_and_after_correction(profile_groups, profile_groups_cor, profile_stats, profile):\n",
    "    \"\"\"\n",
    "    Plots profile and its paired correction profile before and after correction\n",
    "\n",
    "    Args:\n",
    "        group (pandas groupby object): Profiles grouped by profile_id\n",
    "\n",
    "    Returns:\n",
    "        Two plots, one before correction and one after\n",
    "    \"\"\"\n",
    "    group = profile_groups.get_group(profile)\n",
    "    group_cor = profile_groups_cor.get_group(profile)\n",
    "\n",
    "    next_id = int(profile_stats.loc[profile,'pair_group_id'])\n",
    "    next_group = profile_groups.get_group(next_id)\n",
    "    next_group_cor = profile_groups_cor.get_group(next_id)\n",
    "\n",
    "    if profile_stats.loc[profile,'thermal_lag_flag'] == 1:\n",
    "        cor_type = 'TS'\n",
    "    elif profile_stats.loc[profile,'thermal_lag_flag'] == 2:\n",
    "        cor_type = 'SP'\n",
    "    else:\n",
    "        cor_type = 'NO'\n",
    "\n",
    "    temp = group['temperature']\n",
    "    temp_cor = group_cor['ctemp_outside']\n",
    "\n",
    "    salinity = group['salinity']\n",
    "    salinity_cor = group_cor['salt_outside']\n",
    "\n",
    "    depth = group['z']\n",
    "\n",
    "    next_temp = next_group['temperature']\n",
    "    next_temp_cor = next_group_cor['ctemp_outside']\n",
    "\n",
    "    next_salinity = next_group['salinity']\n",
    "    next_salinity_cor = next_group_cor['salt_outside']\n",
    "\n",
    "    next_depth = next_group['z']\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.scatter(salinity, depth, 5, 'b', label=f'Profile {profile}')\n",
    "    ax1.scatter(next_salinity, next_depth, 5, 'g', label=f'Profile {next_id}')\n",
    "    ax1.set_title(f'Profiles {profile} and {next_id} Before Correction')\n",
    "    ax1.legend()\n",
    "    ax1.invert_xaxis()\n",
    "    ax1.set_xlabel('Salinity')\n",
    "    ax1.set_ylabel('Depth (m)')\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(salinity_cor, depth, 5, 'b', label=f'Profile {profile}')\n",
    "    ax2.scatter(next_salinity_cor, next_depth, 5, 'g', label=f'Profile {next_id}')\n",
    "    ax2.set_title(f'Profiles {profile} and {next_id} After {cor_type} Correction')\n",
    "    ax2.legend()\n",
    "    ax2.invert_xaxis()\n",
    "    ax2.set_xlabel('Salinity')\n",
    "    ax2.set_ylabel('Depth (m)')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "before_and_after_correction(profile_groups,profile_groups_cor, profile_stats, 85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netcdfframe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75d83155142a49e16a257f14f1d7a526eae8388f19525aeffe9e9bb861007ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
